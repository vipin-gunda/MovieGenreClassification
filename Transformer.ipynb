{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtpDjf4sHOTp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import ast\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from transformers import AlbertForSequenceClassification, AlbertTokenizer, Trainer, TrainingArguments\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWZM19X4HOTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7413f39c-81d3-434e-8223-ea6bdf707af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 45130 entries, 0 to 45465\n",
            "Data columns (total 26 columns):\n",
            " #   Column                 Non-Null Count  Dtype         \n",
            "---  ------                 --------------  -----         \n",
            " 0   adult                  45130 non-null  object        \n",
            " 1   belongs_to_collection  4481 non-null   object        \n",
            " 2   budget                 45130 non-null  float64       \n",
            " 3   genres                 45130 non-null  object        \n",
            " 4   homepage               7766 non-null   object        \n",
            " 5   id                     45130 non-null  object        \n",
            " 6   imdb_id                45118 non-null  object        \n",
            " 7   original_language      45119 non-null  object        \n",
            " 8   original_title         45130 non-null  object        \n",
            " 9   overview               44435 non-null  object        \n",
            " 10  popularity             45130 non-null  object        \n",
            " 11  poster_path            44808 non-null  object        \n",
            " 12  production_companies   45130 non-null  object        \n",
            " 13  production_countries   45130 non-null  object        \n",
            " 14  release_date           45130 non-null  datetime64[ns]\n",
            " 15  revenue                45130 non-null  float64       \n",
            " 16  runtime                45130 non-null  float64       \n",
            " 17  spoken_languages       45130 non-null  object        \n",
            " 18  status                 45054 non-null  object        \n",
            " 19  tagline                20398 non-null  object        \n",
            " 20  title                  45130 non-null  object        \n",
            " 21  video                  45130 non-null  object        \n",
            " 22  vote_average           45130 non-null  float64       \n",
            " 23  vote_count             45130 non-null  float64       \n",
            " 24  year                   45130 non-null  Int64         \n",
            " 25  genre_list             45130 non-null  object        \n",
            "dtypes: Int64(1), datetime64[ns](1), float64(5), object(19)\n",
            "memory usage: 9.3+ MB\n"
          ]
        }
      ],
      "source": [
        "data_path = 'data/movies'\n",
        "metadata = pd.read_csv(os.path.join(data_path, 'movies_metadata.csv'), low_memory=False)\n",
        "\n",
        "def convert_metadata(metadata):\n",
        "    metadata['release_date'] = pd.to_datetime(metadata['release_date'], errors='coerce')\n",
        "    metadata['budget'] = pd.to_numeric(metadata['budget'], errors='coerce')\n",
        "    metadata['revenue'] = pd.to_numeric(metadata['revenue'], errors='coerce')\n",
        "    metadata['runtime'] = pd.to_numeric(metadata['runtime'], errors='coerce')\n",
        "    return metadata\n",
        "\n",
        "metadata = convert_metadata(metadata)\n",
        "\n",
        "metadata = metadata[pd.notnull(metadata['title'])]\n",
        "metadata = metadata[pd.notnull(metadata['budget'])]\n",
        "metadata = metadata[pd.notnull(metadata['revenue'])]\n",
        "metadata = metadata[pd.notnull(metadata['runtime'])]\n",
        "metadata = metadata[pd.notnull(metadata['release_date'])]\n",
        "\n",
        "metadata['year'] = pd.to_datetime(metadata['release_date'], errors='coerce').dt.year.astype('Int64')\n",
        "metadata['genre_list'] = metadata['genres'].apply(lambda x: [genre['name'] for genre in ast.literal_eval(x)])\n",
        "metadata.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch accelerate -U\n"
      ],
      "metadata": {
        "id": "5A_TsstEQzpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert genre_list to multi-label format\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(metadata['genre_list'])\n",
        "\n",
        "# Load the ALBERT tokenizer and model\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
        "model = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=len(mlb.classes_))\n",
        "\n",
        "# Tokenize the movie titles\n",
        "tokenized_inputs = tokenizer(list(metadata['title']), truncation=True, padding=True, return_tensors=\"pt\")\n",
        "labels = torch.tensor(y, dtype=torch.float32)  # Convert labels to torch tensor\n",
        "\n",
        "# Split the data into training and evaluation sets\n",
        "train_inputs, eval_inputs, train_labels, eval_labels = train_test_split(tokenized_inputs['input_ids'], labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a custom dataset class for training and evaluation\n",
        "class MovieGenreDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            'input_ids': self.encodings[idx],\n",
        "            'attention_mask': self.encodings[idx].bool(),\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create instances of the custom dataset for training and evaluation\n",
        "train_dataset = MovieGenreDataset(train_inputs, train_labels)\n",
        "eval_dataset = MovieGenreDataset(eval_inputs, eval_labels)\n",
        "\n",
        "# Define the Trainer for fine-tuning\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=64,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./fine_tuned_albert_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "wGbHTM_iOPMQ",
        "outputId": "6690a771-39b5-4480-d259-95c5a7f36eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1130' max='1130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1130/1130 06:28, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.287600</td>\n",
              "      <td>0.267689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.266300</td>\n",
              "      <td>0.259359</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_title = \"The Haunting of the Creek\"\n",
        "inputs = tokenizer(test_title, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "inputs.to(torch.device('cuda'))  # Move inputs to CUDA device\n",
        "\n",
        "model.to(torch.device('cuda'))  # Move model to CUDA device\n",
        "outputs = model(**inputs)\n",
        "predicted_scores = torch.sigmoid(outputs.logits).detach().cpu().numpy()  # Move predictions back to CPU\n",
        "\n",
        "# Convert scores to genre labels\n",
        "threshold = 0.0  # Adjust threshold as needed\n",
        "predicted_indices = predicted_scores[0] > threshold\n",
        "predicted_genres = mlb.classes_[predicted_indices]\n",
        "predicted_probabilities = predicted_scores[0][predicted_indices]\n",
        "\n",
        "# Create a list of tuples (genre, probability) and sort by probability in descending order\n",
        "genre_prob_pairs = [(genre, probability) for genre, probability in zip(predicted_genres, predicted_probabilities)]\n",
        "sorted_genre_prob_pairs = sorted(genre_prob_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print the sorted genres and probabilities\n",
        "for genre, probability in sorted_genre_prob_pairs:\n",
        "    print(f\"Genre: {genre}, Probability: {probability:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clFlxo64ST3w",
        "outputId": "efc99c3d-ae61-45d4-989c-4ef4a8cbc50a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genre: Horror, Probability: 0.4646\n",
            "Genre: Thriller, Probability: 0.2860\n",
            "Genre: Action, Probability: 0.2673\n",
            "Genre: Drama, Probability: 0.2576\n",
            "Genre: Science Fiction, Probability: 0.1877\n",
            "Genre: Comedy, Probability: 0.1301\n",
            "Genre: Adventure, Probability: 0.1043\n",
            "Genre: Crime, Probability: 0.0988\n",
            "Genre: Mystery, Probability: 0.0838\n",
            "Genre: Fantasy, Probability: 0.0758\n",
            "Genre: Romance, Probability: 0.0574\n",
            "Genre: Documentary, Probability: 0.0462\n",
            "Genre: Foreign, Probability: 0.0344\n",
            "Genre: War, Probability: 0.0318\n",
            "Genre: Animation, Probability: 0.0303\n",
            "Genre: Western, Probability: 0.0297\n",
            "Genre: Family, Probability: 0.0287\n",
            "Genre: History, Probability: 0.0279\n",
            "Genre: Music, Probability: 0.0174\n",
            "Genre: TV Movie, Probability: 0.0171\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}